# ğŸš€ RunSurge-Master

RunSurge is a distributed computing platform that manages and executes tasks across multiple worker nodes. This repository contains the core backend module of the platform.

---

## ğŸ§± Architecture

RunSurge follows a **Service-Oriented Architecture (SOA)** with the following key components:

- **Master Node**: Coordinates task scheduling, resource allocation, and communication between components.  
- **Worker Nodes**: Execute assigned tasks and process data chunks in parallel.  
- **gRPC Communication Layer**: Enables efficient communication between master and worker nodes.  
- **REST API**: Provides interfaces for user interaction and system management.

---

## âš™ï¸ Core Components

### ğŸ“… 1. Scheduler

The scheduler is responsible for:

- Analyzing job requirements and dependencies.  
- Allocating tasks to appropriate worker nodes based on memory constraints.  
- Creating execution plans to optimize resource usage.  
- Supporting both sequential and parallel execution strategies.  
- Managing task dependencies and data flow between nodes.

Key algorithms:

- Estimate peak memory usage of code blocks.  
- Merge compatible blocks when possible.  
- Split unschedulable blocks into parallel tasks.

---

### ğŸ”€ 2. Parallelizer

The parallelizer enables distributed execution by:

- Building Data Dependency Graphs (DDGs) to analyze block relationships.  
- Estimating memory footprints of functions and code segments.  
- Determining chunking strategies for parallelizable code.  
- Generating execution plans for concurrent task dispatch.

Features:

- Static analysis of Python code.  
- Memory usage estimation.  
- Dependency tracking.

---

### ğŸ§© 3. Aggregator Service

This service combines results from distributed tasks:

- Monitors groups awaiting aggregation.  
- Executes predefined aggregator scripts to merge outputs.  
- Updates status upon completion or failure.  
- Runs independently from task execution to improve modularity.

Purpose:

- Consolidates partial results into a final output.  
- Finalizes jobs once all subtasks are completed.

---

### ğŸ–¥ï¸ 4. Main Backend (FastAPI)

Provides the primary REST API for:

- User authentication and account management.  
- Job submission and status tracking.  
- Node registration and health monitoring.  
- Group and job orchestration.  
- System-wide statistics and logs.

Endpoints:

- `/api/users` â€“ User management  
- `/api/node` â€“ Node registration and status  
- `/api/job` â€“ Job submission and monitoring  
- `/api/auth` â€“ Authentication  
- `/api/group` â€“ Job grouping  
- `/api/statistics` â€“ System metrics

---

### ğŸ”Œ 5. gRPC Application

Facilitates backend-node communication:

- **Master Service**: Manages registration, task assignments, and data exchange.  
- **Worker Client**: Sends and receives job data and updates.  
- **Data Transfer**: Efficiently transmits payloads between nodes.  
- **Heartbeat Mechanism**: Tracks worker node status and availability.

---

## ğŸ› ï¸ Technologies Used

- **Python 3.11** â€“ Core language  
- **FastAPI** â€“ REST API framework  
- **gRPC** â€“ Inter-service communication  
- **SQLAlchemy** â€“ ORM for PostgreSQL  
- **PostgreSQL** â€“ Relational database  
- **Pydantic** â€“ Request/response validation  
- **AsyncIO** â€“ Async I/O for concurrency  
- **semgrep** â€“ Static code analysis for security  
- **Jinja2** â€“ Script templating  
- **NetworkX** â€“ Graph analysis (for DDGs)

---

## ğŸ§° Getting Started

### ğŸ“‹ Requirements

- Python 3.11.9  
- PostgreSQL

### âš™ï¸ Setup

1. Create a virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Create a `.env` file:
   ```env
   # Security
   SECRET_KEY=your-secret-key-here
   ALGORITHM=HS256
   ACCESS_TOKEN_EXPIRE_MINUTES=60
   REFRESH_TOKEN_EXPIRE_DAYS=7

   # Database
   DB_USER=your_db_user
   DB_PASSWORD=your_db_password
   DB_HOST=localhost
   DB_NAME=runsurge
   DB_PORT=5432

   # Master
   MASTER_PORT=8000
   GRPC_PORT=50051
   ```

4. Start the main application:
   ```bash
   python main.py
   ```

5. Start the gRPC server:
   ```bash
   python main_grpc.py
   ```

6. Start the scheduler service:
   ```bash
   python scheduler.py
   ```

7. Start the aggregator service:
   ```bash
   python aggregator.py
   ```

---

## ğŸ“˜ API Documentation

* Swagger UI: [http://localhost:8000/docs](http://localhost:8000/docs)

---

## ğŸ“‚ Project Structure

```
RunSurge-Master/
â”œâ”€â”€ app/                # Main application code
â”‚   â”œâ”€â”€ api/            # API endpoints
â”‚   â”œâ”€â”€ core/           # Core functionality
â”‚   â”œâ”€â”€ db/             # Database models and repositories
â”‚   â”œâ”€â”€ schemas/        # Pydantic models
â”‚   â”œâ”€â”€ services/       # Business logic
â”‚   â”œâ”€â”€ templates/      # Jinja template files
â”‚   â””â”€â”€ utils/          # Utility functions
â”œâ”€â”€ gRPCApp/            # gRPC server implementation
â”œâ”€â”€ Parallelization/    # Code analysis and parallelization
â”‚   â”œâ”€â”€ DDG.py              # Data Dependency Graph builder
â”‚   â”œâ”€â”€ Memory_Estimator.py # Memory usage estimation
â”‚   â””â”€â”€ Parallelizer.py     # Parallelization logic
â”œâ”€â”€ protos_def/         # Protocol buffer definitions
â”œâ”€â”€ scheduler.py        # Task scheduling logic
â”œâ”€â”€ aggregator.py       # Result aggregation service
â”œâ”€â”€ main.py             # FastAPI application entry point
â”œâ”€â”€ main_grpc.py        # gRPC server entry point
â””â”€â”€ requirements.txt    # Project dependencies
```
